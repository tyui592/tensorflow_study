{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 구조는 yolo v1(https://arxiv.org/abs/1506.02640) 논문을 참고했고, fully connected layer 앞부분을 pretrained vgg 16으로 대체하여 구성했음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO net의 feed forward 후 detection procedure는 deepsystems.io의 slide를 참고함.( https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.p )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import scipy.misc as misc\n",
    "import json, os, time, copy\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEG_SIZE = 7\n",
    "IMAGE_SIZE = SEG_SIZE*64\n",
    "CELL_SIZE = int(IMAGE_SIZE/SEG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COCO_ANNOTATIONS_PATH = \"/home/minsisi/COCO_DATASET_ANNOTATIONS/annotations/instances_train2014.json\"\n",
    "COCO_IMAGES_PATH = \"/home/minsisi/COCO_DATASET/train2014/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "json_file = json.load(open(COCO_ANNOTATIONS_PATH,'r'))\n",
    "coco_annotations = json_file['annotations']\n",
    "coco_images_info = json_file['images']\n",
    "coco_categories = json_file['categories']\n",
    "\n",
    "supercategoryName2categoryID = dict()\n",
    "supercategoryID2name = dict()\n",
    "supercategoryID2categoryID = dict()\n",
    "\n",
    "ind = 0 \n",
    "for category in coco_categories:\n",
    "    category_id = category['id']\n",
    "    category_name = category['name']\n",
    "    supercategory_name = category['supercategory']\n",
    "    if supercategory_name in supercategoryName2categoryID:\n",
    "        supercategoryName2categoryID[supercategory_name].append(category_id)\n",
    "    else:\n",
    "        supercategoryName2categoryID[supercategory_name] = list([category_id])\n",
    "        supercategoryID2name[ind] = supercategory_name\n",
    "        ind += 1\n",
    "\n",
    "for k,v in supercategoryID2name.items():\n",
    "    supercategoryID2categoryID[k] = supercategoryName2categoryID[v]\n",
    "\n",
    "del(json_file)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_img_bbox(img, bbox,img_name):\n",
    "    fig, ax = plt.subplots(1, figsize=(8,8))\n",
    "    ax.imshow(img)\n",
    "    for box in bbox:\n",
    "        cenx,ceny,bw,bh = box[0:4]\n",
    "        # minx = int(cenx - bw/2)\n",
    "        # miny = int(ceny - bh/2)\n",
    "        minx = cenx\n",
    "        miny = ceny\n",
    "        sup_id = box[-1]\n",
    "        rect = patches.Rectangle((minx,miny), bw,bh, linewidth=1, edgecolor='r',facecolor='none')\n",
    "        ob_name = supercategoryID2name[sup_id]\n",
    "        plt.text(minx+bw/2, miny, ob_name,fontsize=20, color='green')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_img(x):\n",
    "    return np.clip(x, 0, 255).astype('uint8')\n",
    "\n",
    "def np_one_hot(x, depth=12):\n",
    "    temp =[0]*12\n",
    "    temp[int(x)]=1\n",
    "    return temp\n",
    "\n",
    "def read_img(img_path,IMAGE_SIZE=IMAGE_SIZE):\n",
    "    img = misc.imread(img_path)\n",
    "    # if image is 1 channel stack 3 ch\n",
    "    if not (len(img.shape) == 3 and img.shape[2] == 3):\n",
    "        img = np.dstack((img,img,img))\n",
    "    \n",
    "    return misc.imresize(img, (IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "\n",
    "def find_supercategory_id(category_id):\n",
    "    for k,v in supercategoryID2categoryID.items():\n",
    "        if category_id in v:\n",
    "            return k\n",
    "\n",
    "def get_coco_data(img_info,img_size=IMAGE_SIZE):\n",
    "    \"\"\" \n",
    "        img_info : coco annotation's image information data\n",
    "        return : image, bounding_boxes[object_num, x,y,w,h, super-category id]\n",
    "    \"\"\"\n",
    "    img_file_name = img_info['file_name']\n",
    "    img = read_img(COCO_IMAGES_PATH+img_file_name, img_size)\n",
    "    img_h, img_w = img_info['height'], img_info['width']\n",
    "    img_id = img_info['id']\n",
    "    \n",
    "    bounding_boxes = list() # x,y,w,h, super category id\n",
    "    for annotation in coco_annotations:\n",
    "        if annotation['image_id'] == img_id:\n",
    "            category_id = annotation['category_id']\n",
    "            super_id = find_supercategory_id(category_id)\n",
    "            bbox = annotation['bbox']\n",
    "            # change corresponding box's coord by IMAGE SIZE\n",
    "            bbox= [bbox[0]/img_w, bbox[1]/img_h, bbox[2]/img_w, bbox[3]/img_h]\n",
    "            bbox = [x*img_size for x in bbox]\n",
    "            bounding_boxes.append(bbox+[1,super_id])\n",
    "    return np.expand_dims(img,axis=0), np.array(bounding_boxes,dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_bbox(gboxes):\n",
    "    \"\"\"\n",
    "        ground boxes shape chnage [?x5] -->[7,7,22]\n",
    "        Assign a bounding box to the corresponding cell\n",
    "        and box's x,y,w,h normalize to 0~1\n",
    "    \"\"\"\n",
    "    cell_box = np.zeros([7,7,22], dtype=np.float32)\n",
    "    obj_I = np.zeros([7,7,1], dtype=np.float32)\n",
    "    no_I = np.ones([7,7,1], dtype=np.float32)\n",
    "    for gbox in gboxes:\n",
    "        box_minx, box_miny, box_w, box_h,box_conf, box_cate = gbox\n",
    "        center_x = box_minx + box_w/2\n",
    "        center_y = box_miny + box_h/2\n",
    "        cell_x = int(center_x // CELL_SIZE)\n",
    "        cell_y = int(center_y // CELL_SIZE)\n",
    "        normalize_box = [ (center_x - cell_x*CELL_SIZE)/CELL_SIZE, (center_y-cell_y*CELL_SIZE)/CELL_SIZE, box_w/IMAGE_SIZE, box_h/IMAGE_SIZE, box_conf] \n",
    "        temp = normalize_box + normalize_box+ np_one_hot(box_cate)        \n",
    "        cell_box[cell_y,cell_x,:] = temp\n",
    "        obj_I[cell_y, cell_x,:] = 1\n",
    "        no_I[cell_y, cell_x,:] = 0\n",
    "        \n",
    "    return cell_box,obj_I, no_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrelu(x, alpha=0.1):\n",
    "    return tf.nn.relu(x) - alpha * tf.nn.relu(-x)\n",
    "\n",
    "def conv2d(h, w, stride=1):\n",
    "    return tf.nn.conv2d(h, w, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "\n",
    "def max_pool_2x2(h, k=2, s=2):\n",
    "    return tf.nn.max_pool(h, ksize=[1,k,k,1], strides=[1,s,s,1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "def vgg16(h, train=True):\n",
    "    pooling_architecture = [x*2 for x in [2, 4, 7, 9, 11, 13]]\n",
    "    layer_i = 0\n",
    "    pool_i = 0\n",
    "    vggind = 0\n",
    "    vgg16_weights = np.load('/home/minsisi/VGG_WEIGHTS/vgg16_weights.npy')\n",
    "    while vggind < len(vgg16_weights):\n",
    "        with tf.variable_scope('vgg16_layer'+str(layer_i)):\n",
    "            w = tf.get_variable('conv_w'+str(vggind), initializer=vgg16_weights[vggind], trainable=train)\n",
    "            vggind += 1\n",
    "            b = tf.get_variable('conv_b'+str(vggind), initializer= vgg16_weights[vggind], trainable=train)\n",
    "            vggind += 1\n",
    "            h = lrelu(conv2d(h, w)+b)\n",
    "            layer_i += 1\n",
    "            if vggind == pooling_architecture[pool_i]:\n",
    "                h = max_pool_2x2(h)\n",
    "                pool_i += 1\n",
    "    del(vgg16_weights)\n",
    "    return h\n",
    "\n",
    "def vgg19(h, train=True):\n",
    "    pooling_architecture = [x*2 for x in [2, 4, 8,  11, 14, 16]]\n",
    "    layer_i = 0\n",
    "    pool_i = 0\n",
    "    vggind = 0\n",
    "    vgg19_weights = np.load('vgg19_weights.npy')\n",
    "    while vggind < len(vgg19_weights):\n",
    "        with tf.variable_scope('vgg19_layer'+str(layer_i)):\n",
    "            w = tf.get_variable('conv_w'+str(vggind), initializer=vgg19_weights[vggind], trainable=train)\n",
    "            vggind += 1\n",
    "            b = tf.get_variable('conv_b'+str(vggind), initializer= vgg19_weights[vggind], trainable=train)\n",
    "            vggind += 1\n",
    "            h = lrelu(conv2d(h, w)+b)\n",
    "            layer_i += 1\n",
    "            if vggind == pooling_architecture[pool_i]:\n",
    "                h = max_pool_2x2(h)\n",
    "                pool_i += 1\n",
    "    del(vgg19_weights)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def yolo_net(h):\n",
    "    # preprocess\n",
    "    h = tf.stack([ h[:,:,:,0] - 103.939, h[:,:,:,1] - 116.779,h[:,:,:,2] - 123.68 ], axis=3)\n",
    "    layer_i = 0\n",
    "    # use pretrained vgg 16 network\n",
    "    h = vgg16(h)\n",
    "    \n",
    "    \n",
    "    # # tiny yolo network\n",
    "    # net_info = [16,32,64,128,256,512]\n",
    "    # for filter_num in net_info:\n",
    "    #     with tf.variable_scope('layer'+str(layer_i)):\n",
    "    #         in_ch = h.get_shape().as_list()[-1]\n",
    "    #         w = tf.get_variable('conv_w',[3,3,in_ch, filter_num],dtype=tf.float32, initializer=tf.random_normal_initializer(0,0.05))\n",
    "    #         b = tf.get_variable('conv_b', [filter_num], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "    #         h = lrelu(conv2d(h,w)+b)\n",
    "    #         h = max_pool_2x2(h)\n",
    "    #         layer_i += 1\n",
    "\n",
    "\n",
    "    # conv --> lrelu layers\n",
    "    net_info = [1024,1024,1024]\n",
    "    for filter_num in net_info:\n",
    "        with tf.variable_scope('layer'+str(layer_i)):\n",
    "            in_ch = h.get_shape().as_list()[-1]\n",
    "            w = tf.get_variable('conv_w',[3,3,in_ch, filter_num],dtype=tf.float32, initializer=tf.random_normal_initializer(0,0.05))\n",
    "            b = tf.get_variable('conv_b', [filter_num], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "            h = lrelu(conv2d(h,w)+b)\n",
    "            layer_i += 1\n",
    "    \n",
    "    # flatten 3D tensor\n",
    "    tensor_b, tensor_w,tensor_h, tensor_ch = h.get_shape().as_list()\n",
    "    tensor_b = tf.shape(h)[0]\n",
    "    h = tf.reshape(h, shape=[tensor_b, tensor_h*tensor_w*tensor_ch])\n",
    "    \n",
    "    # fully connected layer\n",
    "    net_info = [4096]\n",
    "    for linear_size in net_info:\n",
    "        with tf.variable_scope('layer'+str(layer_i)):\n",
    "            flattened_size = h.get_shape().as_list()[-1]\n",
    "            w = tf.get_variable('linear_w', [flattened_size, linear_size], dtype=tf.float32, initializer=tf.random_normal_initializer(0,0.05))\n",
    "            b = tf.get_variable('linear_b', [linear_size], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "            h = lrelu(tf.matmul(h,w)+b)\n",
    "            layer_i += 1\n",
    "    \n",
    "    # output layer not use non-linear activation function\n",
    "    output_size = SEG_SIZE*SEG_SIZE*(12+5*2)\n",
    "    with tf.variable_scope('layer'+str(layer_i)):\n",
    "        flattened_size = h.get_shape().as_list()[-1]\n",
    "        w = tf.get_variable('linear_w', [flattened_size, output_size], dtype=tf.float32, initializer=tf.random_normal_initializer(0,0.05))\n",
    "        b = tf.get_variable('linear_b', [output_size], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "        h = tf.matmul(h,w)+b\n",
    "        layer_i += 1\n",
    "    \n",
    "    \n",
    "    # change flattend shape to 3D shape\n",
    "    h = tf.reshape(h,[tensor_b, SEG_SIZE, SEG_SIZE, (12+5*2)])\n",
    "    return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersection(a,b):\n",
    "    x = max(a[0], b[0])\n",
    "    y = max(a[1], b[1])\n",
    "    w = min(a[0]+a[2], b[0]+b[2]) - x\n",
    "    h = min(a[1]+a[3], b[1]+b[3]) - y\n",
    "    if w<0 or h<0: return (x,y,0,0)\n",
    "    return (x, y, w, h)\n",
    "\n",
    "def calc_iou(a,b):\n",
    "    intersec = intersection(a,b)\n",
    "    box1_size = a[2]*a[3]\n",
    "    box2_size = b[2]*b[3]\n",
    "    intersection_size = intersec[2]*intersec[3]\n",
    "    return intersection_size / (box1_size + box2_size - intersection_size)\n",
    "\n",
    "def add_offset(bbox,cell_id):\n",
    "    box_cenx, box_ceny, box_w, box_h = bbox\n",
    "    box_w = box_w*IMAGE_SIZE\n",
    "    box_h = box_h*IMAGE_SIZE\n",
    "    \n",
    "    x_offset = (cell_id%SEG_SIZE)*CELL_SIZE\n",
    "    y_offset = (cell_id//SEG_SIZE)*CELL_SIZE\n",
    "    box_x = box_cenx*CELL_SIZE - (box_w/2)\n",
    "    box_y = box_ceny*CELL_SIZE - (box_h/2)\n",
    "    return [box_x+x_offset,box_y+y_offset , box_w, box_h]\n",
    "\n",
    "# Non Maximun Suppression\n",
    "def NMS(cls_scores,flat_pred_box, iou_threshold,score_threshold):\n",
    "    cls_score_mat = copy.deepcopy(cls_scores)\n",
    "    for i in range(len(cls_score_mat)):\n",
    "        # sort by row (per one class)\n",
    "        temp_arg = np.argsort( - cls_score_mat[i,:])\n",
    "        sorted_scores = cls_score_mat[i, temp_arg] # sorting\n",
    "\n",
    "        # nms algorithm\n",
    "        for j in range(len(sorted_scores)):\n",
    "            if sorted_scores[j] == 0:\n",
    "                continue\n",
    "\n",
    "            # j is 0~97 , 49*2 boxes\n",
    "            # change j to cell, box id\n",
    "            cell_id = temp_arg[j] % (SEG_SIZE**2) # 0~48\n",
    "            box_id = temp_arg[j] // (SEG_SIZE**2) # 0,1\n",
    "            bbox_max = add_offset(flat_pred_box[cell_id, box_id*5 : box_id*5+4], cell_id) # get box's x, y, w, h\n",
    "            \n",
    "            for k in range(len(cls_score_mat[i,j+1:])-1):\n",
    "                cell_id2 = temp_arg[k+j+1] % (SEG_SIZE**2)\n",
    "                box_id2 = temp_arg[k+j+1] // (SEG_SIZE**2)\n",
    "                bbox_cur = add_offset(flat_pred_box[cell_id2, box_id2*5 : box_id2*5+4], cell_id2)\n",
    "                if calc_iou(bbox_max, bbox_cur) > iou_threshold :\n",
    "                    sorted_scores[j+k+1] = 0\n",
    "                    cls_score_mat[i, temp_arg[k+j+1]] = 0\n",
    "\n",
    "    #\n",
    "    cls_score_mat[cls_score_mat < score_threshold] = 0\n",
    "    return cls_score_mat\n",
    "\n",
    "# inference \n",
    "def detection_procedure(pred_boxes,th1= 0.3, th2 = 0.5, th3= 0.0):\n",
    "    # 7,7,22 --> 49,22\n",
    "    flat_pred_box = np.reshape(pred_boxes, [-1, pred_boxes.shape[-1]])\n",
    "\n",
    "    cls_score_mat = np.concatenate([flat_pred_box[:,4:5] * flat_pred_box[:,10:], flat_pred_box[:,9:10] * flat_pred_box[:,10:]] ,0)\n",
    "    cls_score_mat = np.transpose(cls_score_mat) \n",
    "    \n",
    "    # thresholding \n",
    "    temp_ind = cls_score_mat < th1\n",
    "    cls_score_mat[temp_ind] = 0\n",
    "\n",
    "    # Non Maximun Suppression\n",
    "    nms_result =  NMS(cls_score_mat,flat_pred_box, th2,th3)\n",
    "    \n",
    "    detect_obj = list()\n",
    "    ind =0 \n",
    "    for cls_per_box in nms_result.T:\n",
    "        if np.max(cls_per_box) > 0:\n",
    "            box_id = ind // SEG_SIZE**2\n",
    "            cell_id = ind % SEG_SIZE**2\n",
    "            bbox = flat_pred_box[cell_id, box_id*5 : box_id*5+4] # get box's x,y,w,h\n",
    "            bbox = add_offset(bbox, cell_id)\n",
    "            category_id = np.argmax(cls_per_box)\n",
    "            detect_obj.append(bbox+[category_id])         \n",
    "\n",
    "        ind += 1\n",
    "    return detect_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(model_load_path='', test_image_path=''):   \n",
    "    \n",
    "    inp_img = tf.placeholder(name='input_image',shape=[None,IMAGE_SIZE, IMAGE_SIZE, 3], dtype= tf.float32)\n",
    "    tout = yolo_net(inp_img)\n",
    "    # get vgg for style's weights\n",
    "    reader = tf.train.NewCheckpointReader(model_load_path)\n",
    "    restore_dict = dict()\n",
    "    for v in tf.global_variables():\n",
    "        tensor_name= v.name.split(':')[0]\n",
    "        if reader.has_tensor(tensor_name):\n",
    "            print('has tensor : ',tensor_name)\n",
    "            restore_dict[tensor_name] = v\n",
    "    #\n",
    "    saver = tf.train.Saver(restore_dict)\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, model_load_path)\n",
    "    \n",
    "    \n",
    "    feed_forward_times = []\n",
    "    detect_times = []\n",
    "\n",
    "    test_image_names = os.listdir(test_image_path)\n",
    "    for name in test_image_names:\n",
    "        img_name = test_image_path+name\n",
    "        img = read_img(img_name)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        t1 = time.time()\n",
    "        test_tout = sess.run(tout, {inp_img:img})\n",
    "        feed_forward_times.append(time.time()-t1)\n",
    "\n",
    "        t1 = time.time()\n",
    "        detected = detection_procedure(test_tout)\n",
    "        detect_times.append(time.time()- t1)\n",
    "        plot_img_bbox(img[0,...], detected, 'none')\n",
    "\n",
    "    print(\"%s: Average feed forward time : %2.4f, Average detection procedure time : %2.4f\"%(datetime.now(),np.mean(feed_forward_times), np.mean(detect_times)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main(model_load_path='/home/minsisi/TRAINED_MODELS/yolo/yolo_tiny_model.ckpt', test_image_path='/home/minsisi/IMAGES/yolo_test_images/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
